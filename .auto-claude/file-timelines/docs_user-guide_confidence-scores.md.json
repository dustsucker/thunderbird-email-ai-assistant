{
  "file_path": "docs/user-guide/confidence-scores.md",
  "main_branch_history": [],
  "task_views": {
    "003-confidence-score-display-and-threshold-configurati": {
      "task_id": "003-confidence-score-display-and-threshold-configurati",
      "branch_point": {
        "commit_hash": "f6a57e8f6ff34822855d2c5f711f425bd9bc6897",
        "content": "",
        "timestamp": "2026-01-05T14:48:03.044500"
      },
      "worktree_state": {
        "content": "# Confidence Scores and Threshold Configuration - User Guide\n\n## Overview\n\nThe Email Assistant provides **confidence scores** for AI-powered email classifications to help you understand how certain the AI is about its tag suggestions. This transparency enables you to make informed decisions about which tags to apply and when manual review is needed.\n\n### What is a Confidence Score?\n\nA **confidence score** (0-100%) indicates how certain the AI model is that an email should be tagged with a particular category:\n\n- **100%**: Completely certain\n- **80-99%**: Highly confident\n- **60-79%**: Moderately confident\n- **40-59%**: Somewhat uncertain\n- **0-39%**: Very uncertain\n\n### Why Confidence Scores Matter\n\n- **Prevent Misclassification**: Low-confidence classifications may be incorrect\n- **Quality Control**: Review only uncertain classifications instead of everything\n- **Transparency**: Understand AI decision-making, not just black-box results\n- **Customizable Control**: Set thresholds that match your risk tolerance\n\n## Understanding Confidence Indicators\n\n### Visual Color Coding\n\nThe Email Assistant uses consistent color coding across all UI components:\n\n| Confidence Level | Range | Color | Indicator |\n|-----------------|-------|-------|-----------|\n| **High** | \u226580% | \ud83d\udfe2 Green | High certainty - safe to auto-apply |\n| **Medium** | 60-80% | \ud83d\udfe1 Yellow | Moderate certainty - may need review |\n| **Low** | <60% | \ud83d\udd34 Red | Low certainty - manual review recommended |\n\n### Where Confidence Scores Appear\n\n1. **Analysis Notifications** (after email analysis)\n   - Overall confidence score with emoji indicator\n   - List of auto-applied tags (\u2713)\n   - List of tags needing manual review (\u26a0) with threshold comparison\n\n2. **Review Queue** (Options page)\n   - Each item shows confidence percentage\n   - Color-coded confidence badges\n   - Tag-level confidence vs. threshold comparison\n   - Statistics showing average confidence\n\n3. **Analysis History** (Options page)\n   - Overall statistics (average confidence, high/medium/low breakdown)\n   - Confidence distribution histogram\n   - Per-tag statistics (average, min, max)\n   - Historical confidence trend chart\n\n## Configuring Confidence Thresholds\n\n### Global Threshold Setting\n\nThe **global confidence threshold** determines the minimum confidence required for tags to be automatically applied. Tags below this threshold require manual review.\n\n#### Default Setting\n- **Default threshold**: 70%\n- **Recommended range**: 60-85%\n\n#### How to Configure\n\n1. Open Thunderbird\n2. Go to **Tools \u2192 Add-ons and Themes**\n3. Find \"Email Assistant\" and click **Options**\n4. Navigate to the **\"Analyse-Einstellungen\"** tab\n5. Use the slider or number input to set your desired threshold (0-100%)\n6. Click **\"Save\"** to apply changes\n7. Click **\"Reset\"** to return to the default (70%)\n\n#### Impact\n\n- **Higher threshold** (e.g., 85%): Fewer auto-applied tags, more manual review\n  - \u2705 Pros: Fewer false positives, higher accuracy\n  - \u274c Cons: More emails to review manually\n\n- **Lower threshold** (e.g., 60%): More auto-applied tags, less manual review\n  - \u2705 Pros: Less manual effort, more automation\n  - \u274c Cons: More potential misclassifications\n\n### Per-Tag Threshold Overrides\n\nYou can set **custom thresholds for individual tags** to have stricter or more lenient requirements based on the tag's importance.\n\n#### Use Cases\n\n- **High-stakes tags** (e.g., `is_urgent`, `is_legal`): Set higher threshold (85-90%)\n- **Broad categories** (e.g., `is_newsletter`): Set lower threshold (50-60%)\n- **Niche tags** (e.g., `is_conference`): Set higher threshold if rarely used\n\n#### How to Configure\n\n1. Open **Tools \u2192 Add-ons and Themes \u2192 Email Assistant \u2192 Options**\n2. Navigate to the **\"Tags verwalten\"** tab\n3. Click the **edit icon** (\u270f\ufe0f) next to the tag you want to configure\n4. In the tag edit modal, find the **\"Confidence Threshold\"** section\n5. Use the slider or number input to set a custom threshold (0-100%)\n   - Leave empty to use the global threshold\n6. Click **\"Save\"** to save the tag configuration\n\n#### Visual Indicators\n\nAfter setting a per-tag threshold, the tag list displays:\n- **Percentage badge** (e.g., \"85%\"): Custom threshold configured\n- **\"Global\" badge**: Using the global threshold\n\n#### Example Configuration\n\n```\nGlobal threshold: 70%\n\nTag configurations:\n- is_urgent:          90% (stricter - only auto-apply when very certain)\n- is_legal:           85% (stricter - legal emails need high confidence)\n- is_business:        70% (using global threshold)\n- is_newsletter:      50% (more lenient - broad category)\n- is_personal:        70% (using global threshold)\n```\n\n## How Threshold-Based Filtering Works\n\n### The Decision Process\n\nWhen an email is analyzed, the AI returns tags with confidence scores:\n\n```\nAnalysis Result:\n- is_business: 75%\n- is_newsletter: 45%\n- is_urgent: 82%\n```\n\n**With threshold configuration:**\n- Global threshold: 70%\n- is_urgent override: 90%\n\n**Filtering result:**\n```\n\u2713 Auto-applied:\n  - is_business (75% \u2265 70%)\n  - (is_urgent NOT applied because 82% < 90%)\n\n\u26a0 Manual review required:\n  - is_urgent (82% < 90%)\n  - is_newsletter (45% < 70%)\n```\n\n### What Happens Next\n\n1. **Auto-applied tags**: Immediately added to the email\n2. **Manual review tags**: Added to the Review Queue for your decision\n3. **Notification**: Shows which tags were applied vs. need review\n\n## Using the Review Queue\n\nThe **Review Queue** (Review-Warteschlange) is where you manage classifications that fell below the confidence threshold.\n\n### Accessing the Review Queue\n\n1. Open **Tools \u2192 Add-ons and Themes \u2192 Email Assistant \u2192 Options**\n2. Click the **\"Review-Warteschlange\"** tab\n\n### Review Queue Features\n\n#### Filtering\n- **By status**: Pending, Approved, Rejected, Ignored\n- **By confidence range**: 0-50%, 50-60%, 60-70%, 70-80%, 80-100%\n- **By tags**: Show only items with specific tags\n\n#### Sorting\n- **Confidence** (ascending/descending): Review least confident first\n- **Date** (ascending/descending): Review newest or oldest first\n\n#### Actions\nFor each review item, you can:\n- **Approve**: Apply the tags despite low confidence\n- **Reject**: Don't apply the tags\n- **Ignore**: Remove from queue without applying (won't reappear)\n\n#### Bulk Actions\n- **\"Clear Reviewed\"**: Remove all non-pending items from the queue\n\n### Best Practices\n\n1. **Review regularly**: Don't let the queue grow too large\n2. **Filter by confidence**: Focus on the least confident items first\n3. **Provide feedback**: Your review decisions can inform future threshold adjustments\n4. **Check patterns**: If certain tags consistently appear, adjust their thresholds\n\n## Analysis History and Statistics\n\nThe **Analysis History** (Analyse-Historie) tab provides comprehensive statistics about your AI classifications over time.\n\n### Accessing Analysis History\n\n1. Open **Tools \u2192 Add-ons and Themes \u2192 Email Assistant \u2192 Options**\n2. Click the **\"Analyse-Historie\"** tab\n\n### Available Statistics\n\n#### Overall Statistics\n- **Total analyses**: Number of emails processed\n- **Average confidence**: Mean confidence across all classifications\n- **Confidence breakdown**: Count and percentage of high/medium/low classifications\n\n#### Confidence Distribution Histogram\nVisual bar chart showing how classifications are distributed across confidence ranges:\n- 0-20%, 20-40%, 40-60%, 60-80%, 80-100%\n\n#### Per-Tag Statistics\nFor each tag:\n- **Usage count**: How many times the tag was applied\n- **Average confidence**: Mean confidence for this tag\n- **Min/Max confidence**: Range of confidence scores\n\n#### Confidence Trend Chart\nLine chart showing average confidence over time (last 30 data points)\n\n### Using History to Optimize Thresholds\n\n1. **Check low-confidence tags**: Tags with consistently low averages may need better prompts\n2. **Identify misclassifications**: Patterns in rejected items indicate threshold issues\n3. **Track improvement**: See if confidence scores improve over time\n4. **Evaluate provider performance**: Compare confidence between different AI models\n\n## Best Practices for Threshold Configuration\n\n### Starting Out (First-Time Users)\n\n1. **Use the default** (70%) for the first few days\n2. **Review the queue daily** to understand typical confidence scores\n3. **Check analysis history** after processing 50+ emails\n4. **Adjust gradually** based on your experience\n\n### Setting Global Threshold\n\n#### Conservative Approach (High Accuracy)\n- **Threshold**: 80-85%\n- **Best for**: Critical workflows, low tolerance for errors\n- **Trade-off**: More manual review required\n\n#### Balanced Approach (Recommended)\n- **Threshold**: 70-75%\n- **Best for**: General use, balanced automation and accuracy\n- **Trade-off**: Moderate manual review\n\n#### Aggressive Approach (High Automation)\n- **Threshold**: 55-65%\n- **Best for**: High volume, tolerance for some errors\n- **Trade-off**: More false positives, less accurate\n\n### Setting Per-Tag Thresholds\n\n#### Tags Requiring High Confidence (85-90%)\n- `is_urgent`: Only mark urgent if very certain\n- `is_legal`: Legal emails need high certainty\n- `is_payment`: Financial transactions require accuracy\n- `is_confidential`: Sensitive content needs verification\n\n#### Tags Requiring Moderate Confidence (70-80%)\n- `is_business`: General business category\n- `is_personal`: Personal correspondence\n- `is_work_related`: Professional context\n- `is_project_x`: Specific project (use your judgment)\n\n#### Tags Requiring Lower Confidence (50-65%)\n- `is_newsletter`: Broad category, minor consequences if wrong\n- `is_promotion`: Marketing emails, not critical\n- `is_notification`: Automated messages, low stakes\n\n### Avoiding Common Mistakes\n\n\u274c **Don't set threshold to 100%**: AI models rarely achieve absolute certainty\n\u274c **Don't set threshold below 50%**: Too many false positives\n\u274c **Don't ignore the review queue**: Low-confidence items need attention\n\u274c **Don't set all tags to the same threshold**: Per-tag customization is powerful\n\u274c **Don't change thresholds too frequently**: Give each setting time to prove itself\n\n\u2705 **Do monitor statistics**: Use analysis history to inform decisions\n\u2705 **Do adjust based on patterns**: Certain tags may consistently need adjustment\n\u2705 **Do review rejected items**: Learn from errors to improve prompts or thresholds\n\u2705 **Do experiment gradually**: Small adjustments (\u00b15%) work best\n\n## Troubleshooting\n\n### Problem: Too Many Items in Review Queue\n\n#### Symptom\nReview queue growing faster than you can process it\n\n#### Possible Causes\n1. **Threshold set too high**: Auto-applied tags are too rare\n2. **Model confidence low**: AI model struggling with your emails\n3. **Tag prompts unclear**: AI confused by tag definitions\n\n#### Solutions\n\n**Check your threshold:**\n1. Open **Analyse-Einstellungen** tab\n2. If threshold > 80%, consider lowering to 70-75%\n3. Monitor queue size for a few days\n\n**Review analysis history:**\n1. Open **Analyse-Historie** tab\n2. Check **average confidence** across all classifications\n3. If average < 60%, consider switching AI providers or models\n\n**Audit tag prompts:**\n1. Open **Tags verwalten** tab\n2. Review prompts for tags frequently in the queue\n3. Clarify ambiguous prompts (e.g., \"business email\" \u2192 \"work-related B2B communication\")\n\n### Problem: Too Many False Positives (Incorrect Auto-Applied Tags)\n\n#### Symptom\nTags are being applied incorrectly without manual review\n\n#### Possible Causes\n1. **Threshold set too low**: Low-confidence tags being auto-applied\n2. **Per-tag threshold too lenient**: Specific tag needs higher threshold\n3. **Model overconfident**: AI model consistently overestimates certainty\n\n#### Solutions\n\n**Raise global threshold:**\n1. Open **Analyse-Einstellungen** tab\n2. Increase threshold by 5-10% (e.g., 70% \u2192 75%)\n3. Monitor accuracy for a few days\n\n**Set per-tag overrides:**\n1. Identify problematic tags from rejected items in review queue\n2. Open **Tags verwalten** tab\n3. Edit problematic tags and set higher thresholds (e.g., 85-90%)\n\n**Check model calibration:**\n1. Open **Analyse-Historie** tab\n2. Look at confidence distribution\n3. If heavily skewed toward high confidence with many errors, consider switching providers\n\n### Problem: Per-Tag Threshold Not Working\n\n#### Symptom\nTag with custom threshold still uses global threshold\n\n#### Solutions\n\n**Verify threshold was saved:**\n1. Open **Tags verwalten** tab\n2. Check that the tag shows a percentage badge (not \"Global\")\n3. If showing \"Global\", re-edit the tag and save again\n\n**Check for conflicts:**\n1. Ensure threshold value is between 0-100\n2. Don't leave the field empty if you want a custom threshold\n3. Click \"Save\" button (not just closing the modal)\n\n**Restart Thunderbird:**\n1. Close Thunderbird completely\n2. Reopen and check if threshold persists\n3. If not, check browser console for errors (F12 \u2192 Console)\n\n### Problem: Confidence Scores Seem Wrong\n\n#### Symptom\nConfidence scores don't match email content (e.g., obvious business email tagged with 40% confidence)\n\n#### Possible Causes\n1. **Poor tag prompt**: AI unclear what to look for\n2. **Model mismatch**: Model not suited for your email types\n3. **Complex email**: Email has mixed or ambiguous content\n\n#### Solutions\n\n**Review tag prompts:**\n1. Open **Tags verwalten** tab\n2. Check prompts for low-confidence tags\n3. Add examples or clarification to prompts\n4. Test with example emails\n\n**Try different provider:**\n1. Open **Allgemein** tab\n2. Switch to a different AI provider (e.g., Ollama \u2192 Claude)\n3. Process similar emails and compare confidence scores\n\n**Accept some uncertainty:**\n1. Some emails are genuinely ambiguous\n2. Set appropriate thresholds and use manual review\n3. Focus on high-confidence classifications, accept low-confidence ones need review\n\n### Problem: No Confidence Scores Showing\n\n#### Symptom\nTags are applied but no confidence percentages displayed\n\n#### Solutions\n\n**Check provider compatibility:**\n1. Open **Allgemein** tab\n2. Verify your provider supports confidence scores\n3. Supported providers: OpenAI, Claude, Gemini, Mistral, DeepSeek, Ollama\n\n**Check for errors:**\n1. Open browser console (F12 \u2192 Console)\n2. Look for red error messages\n3. Check background script console in Thunderbird DevTools\n\n**Update extension:**\n1. Ensure you have the latest version\n2. Check for updates in **Tools \u2192 Add-ons and Themes**\n3. Reinstall if necessary\n\n### Problem: Statistics Not Updating\n\n#### Symptom\nAnalysis history shows old data or missing recent analyses\n\n#### Solutions\n\n**Refresh the page:**\n1. Press F5 or click refresh button\n2. Navigate away from and back to **Analyse-Historie** tab\n\n**Check storage:**\n1. Open browser console (F12 \u2192 Console)\n2. Run: `browser.storage.local.get('analysisHistory')`\n3. Verify data exists and is recent\n\n**Clear cache:**\n1. Open **Tools \u2192 Options \u2192 Privacy & Security**\n2. Clear cache and site data\n3. Restart Thunderbird\n\n## Advanced Topics\n\n### Confidence Score Calculation\n\nConfidence scores are calculated differently by each AI provider:\n\n- **OpenAI (GPT)**: Logprob-based confidence from token probabilities\n- **Claude**: Internal certainty estimation\n- **Gemini**: Model confidence scores\n- **Mistral**: Probability-based confidence\n- **Ollama**: Local model confidence estimation\n- **DeepSeek**: Internal confidence metrics\n\nAll scores are **normalized to 0-100 scale** by the Email Assistant for consistency.\n\n### Thresholds and Message Filters\n\nConfidence thresholds work **independently** from Thunderbird's message filters:\n\n1. **AI analysis runs** when email is received\n2. **Tags applied** based on confidence thresholds\n3. **Message filters run** periodically (you configure this)\n4. **Filters use tags** to move/copy/delete emails\n\n**Best practice**: Set message filters to run every 5-10 minutes to allow time for AI analysis to complete.\n\n### Exporting Analysis Data\n\nWhile not currently available in the UI, you can export analysis history via the browser console:\n\n```javascript\n// Open DevTools Console (F12) and run:\nbrowser.storage.local.get('analysisHistory').then(result => {\n  const data = result.analysisHistory;\n  console.log(JSON.stringify(data, null, 2));\n  // Copy output and save to file\n});\n```\n\n### Privacy Considerations\n\nConfidence scores and analysis history are stored **locally** in Thunderbird's storage:\n\n- **Never sent to external servers** (except AI API during analysis)\n- **Synced across devices** if you use Thunderbird Sync\n- **Deleted when extension is uninstalled**\n\n**Tip**: Clear analysis history periodically if privacy is a concern:\n1. Open **Analyse-Historie** tab\n2. Click **\"Verlauf l\u00f6schen\"** button (if available) or clear via browser console\n\n## FAQ\n\n### Q: What confidence score should I use?\n\n**A:** Start with the default (70%). After processing 50+ emails, check your analysis history. If average confidence is high (>80%), you can raise the threshold. If average is low (<65%), consider lowering it or switching AI models.\n\n### Q: Can I use different thresholds for different email accounts?\n\n**A:** Not directly. Thresholds are global across all accounts. However, you can use per-tag thresholds strategically (e.g., different tag sets for different accounts) or file a feature request for account-specific settings.\n\n### Q: Do confidence scores work with all AI providers?\n\n**A:** Most major providers support confidence scores: OpenAI, Claude, Gemini, Mistral, DeepSeek, and Ollama. Check provider documentation for details on how they calculate confidence.\n\n### Q: How often should I review my review queue?\n\n**A:** Daily is ideal for busy inboxes. Weekly minimum for low volume. Don't let it grow beyond 100 items or it becomes unmanageable.\n\n### Q: What happens if I set threshold to 0% or 100%?\n\n**A:**\n- **0%**: All tags auto-applied, no manual review (not recommended)\n- **100%**: Almost no tags auto-applied, everything goes to review queue (defeats the purpose)\n\n**Recommendation**: Stay within 50-90% range.\n\n### Q: Can I disable confidence thresholds entirely?\n\n**A:** Yes, set threshold to 0% to auto-apply all tags without manual review. However, this is not recommended as you lose the quality control benefits of the confidence system.\n\n### Q: How do I know if my thresholds are working well?\n\n**A:**\n1. Check **Review Queue** size: Should be manageable (10-30% of analyzed emails)\n2. Review **rejected items**: Should be relatively rare (<10% of reviewed items)\n3. Monitor **Analysis History**: Average confidence should align with your threshold\n4. Trust your judgment: If you're approving most review queue items, lower threshold. If rejecting most, raise it.\n\n### Q: Will the AI learn from my review decisions?\n\n**A:** Not automatically. The Email Assistant doesn't currently support feedback learning. However, you can manually improve prompts based on patterns in rejected/approved items, which will improve future classifications.\n\n## Getting Help\n\n### Documentation\n- **Main README**: [README.md](../../README.md)\n- **E2E Testing**: [docs/E2E-TESTING.md](../E2E-TESTING.md)\n- **Architecture**: [ARCHITECTURE.md](../../ARCHITECTURE.md)\n\n### Reporting Issues\nFound a bug or have a feature request? Please open an issue on GitHub with:\n- Thunderbird version\n- Email Assistant version\n- AI provider and model used\n- Steps to reproduce\n- Expected vs. actual behavior\n- Console errors (F12 \u2192 Console)\n\n### Feature Requests\nWe welcome suggestions for improving confidence score functionality:\n- Additional visualization options\n- Export/import of analysis history\n- Account-specific thresholds\n- Confidence score calibration tools\n- Feedback learning from review decisions\n\n---\n\n**Last Updated**: 2026-01-05\n**Version**: 1.0.4\n**Feature**: Confidence Score Display and Threshold Configuration\n",
        "last_modified": "2026-01-05T19:59:00.202072"
      },
      "task_intent": {
        "title": "Confidence Score Display and Threshold Configuration",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-05T14:48:03.068781",
  "last_updated": "2026-01-05T14:48:03.072258"
}